{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 備註--------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#vectorizer=CountVectorizer()\n",
    "#transformer=TfidfTransformer()\n",
    "#tfidf=transformer.fit_transform(vectorizer.fit_transform(corpus))\n",
    "\n",
    "#等價於：\n",
    "\n",
    "#transformer=TfidfVectorizer()\n",
    "#tfidf2=transformer.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ---------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#|--20news-bydate\n",
    "#            |--20news-bydate-train\n",
    "#            |--20news-bydate-test\n",
    "\n",
    "twenty_train = fetch_20newsgroups(subset='train')\n",
    "twenty_test = fetch_20newsgroups(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alt.atheism',\n",
      " 'comp.graphics',\n",
      " 'comp.os.ms-windows.misc',\n",
      " 'comp.sys.ibm.pc.hardware',\n",
      " 'comp.sys.mac.hardware',\n",
      " 'comp.windows.x',\n",
      " 'misc.forsale',\n",
      " 'rec.autos',\n",
      " 'rec.motorcycles',\n",
      " 'rec.sport.baseball',\n",
      " 'rec.sport.hockey',\n",
      " 'sci.crypt',\n",
      " 'sci.electronics',\n",
      " 'sci.med',\n",
      " 'sci.space',\n",
      " 'soc.religion.christian',\n",
      " 'talk.politics.guns',\n",
      " 'talk.politics.mideast',\n",
      " 'talk.politics.misc',\n",
      " 'talk.religion.misc']\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "pprint(list(twenty_train.target_names))\n",
    "# 20 newsgroups dataset \n",
    "# 18000 newsgroups posts on 20 topics split in two subsets: one for training  and  one for testing . "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 11314, 11314, 7532)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(twenty_train.target_names),len(twenty_train.data),len(twenty_train.filenames),len(twenty_test.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "From: lerxst@wam.umd.edu (where's my thing)\n",
      "Subject: WHAT car is this!?\n",
      "Nntp-Posting-Host: rac3.wam.umd.edu\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(twenty_train.data[0].split(\"\\n\")[:3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rec.autos\n"
     ]
    }
   ],
   "source": [
    "print(twenty_train.target_names[twenty_train.target[0]])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 7,  4,  4,  1, 14, 16, 13,  3,  2,  4])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "twenty_train.target[:10]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 計算詞頻"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 129796)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer(stop_words=\"english\",decode_error='ignore')\n",
    "X_train_counts = count_vect.fit_transform(twenty_train.data)\n",
    "X_train_counts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11314, 129796)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "X_train_tfidf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 貝氏分類器"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB().fit(X_train_tfidf,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'God is love' => soc.religion.christian\n",
      "'OpenGL on the GPU is fast' => comp.graphics\n"
     ]
    }
   ],
   "source": [
    "# 對新的樣本進行預測\n",
    "docs_new = ['God is love','OpenGL on the GPU is fast']\n",
    "X_new_counts = count_vect.transform(docs_new)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "for doc,category in zip(docs_new,predicted):\n",
    "    print('%r => %s' % (doc,twenty_train.target_names[category]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 分類效果"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "text_clf = Pipeline([('vect',CountVectorizer(stop_words=\"english\",decode_error='ignore')),\n",
    "                    ('tfidf',TfidfTransformer()),\n",
    "                    ('clf',MultinomialNB()),\n",
    "                    ])\n",
    "\n",
    "text_clf = text_clf.fit(twenty_train.data,twenty_train.target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "docs_test = twenty_test.data\n",
    "y_pred = text_clf.predict(docs_test)\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.2f' % accuracy_score(twenty_test.target, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用svm分類"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.82\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "text_clf_2 = Pipeline([('vect',CountVectorizer(stop_words='english',decode_error='ignore')),\n",
    "                      ('tfidf',TfidfTransformer()),\n",
    "                      ('clf',SGDClassifier(loss = 'hinge',penalty = 'l2',\n",
    "                                          alpha = 1e-3,n_iter = 5, random_state = 42)),\n",
    "                      ])\n",
    "\n",
    "_ = text_clf_2.fit(twenty_train.data,twenty_train.target)\n",
    "y_pred = text_clf_2.predict(docs_test)\n",
    "print('Accuracy: %.2f' % accuracy_score(twenty_test.target, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          precision    recall  f1-score   support\n",
      "\n",
      "             alt.atheism       0.72      0.71      0.71       319\n",
      "           comp.graphics       0.79      0.70      0.74       389\n",
      " comp.os.ms-windows.misc       0.73      0.77      0.75       394\n",
      "comp.sys.ibm.pc.hardware       0.71      0.68      0.69       392\n",
      "   comp.sys.mac.hardware       0.82      0.82      0.82       385\n",
      "          comp.windows.x       0.84      0.77      0.80       395\n",
      "            misc.forsale       0.82      0.87      0.85       390\n",
      "               rec.autos       0.91      0.89      0.90       396\n",
      "         rec.motorcycles       0.92      0.97      0.94       398\n",
      "      rec.sport.baseball       0.90      0.91      0.90       397\n",
      "        rec.sport.hockey       0.86      0.98      0.92       399\n",
      "               sci.crypt       0.85      0.96      0.90       396\n",
      "         sci.electronics       0.81      0.62      0.70       393\n",
      "                 sci.med       0.90      0.87      0.88       396\n",
      "               sci.space       0.83      0.96      0.89       394\n",
      "  soc.religion.christian       0.74      0.93      0.82       398\n",
      "      talk.politics.guns       0.70      0.93      0.80       364\n",
      "   talk.politics.mideast       0.92      0.93      0.92       376\n",
      "      talk.politics.misc       0.89      0.56      0.69       310\n",
      "      talk.religion.misc       0.82      0.39      0.53       251\n",
      "\n",
      "             avg / total       0.83      0.82      0.82      7532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(twenty_test.target,y_pred,\n",
    "                                   target_names = twenty_test.target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[225,   1,   0,   1,   0,   1,   2,   0,   2,   3,   0,   2,   1,\n",
       "          8,   6,  47,   2,   6,   1,  11],\n",
       "       [  2, 273,  20,   8,   9,  28,   3,   1,   4,   7,   3,   9,   4,\n",
       "          1,   9,   2,   2,   3,   0,   1],\n",
       "       [  0,  10, 304,  24,  11,  11,   1,   2,   1,   5,   3,   8,   2,\n",
       "          1,   7,   1,   0,   1,   0,   2],\n",
       "       [  3,   8,  32, 265,  19,   4,  17,   2,   3,   3,   2,   3,  20,\n",
       "          1,   5,   0,   1,   2,   1,   1],\n",
       "       [  1,   4,   8,  26, 315,   2,  10,   0,   1,   2,   3,   1,   6,\n",
       "          1,   1,   0,   2,   0,   2,   0],\n",
       "       [  1,  29,  41,   0,   3, 303,   2,   0,   1,   1,   1,   2,   1,\n",
       "          1,   7,   1,   1,   0,   0,   0],\n",
       "       [  0,   3,   0,  18,   6,   0, 340,   8,   1,   2,   3,   1,   3,\n",
       "          2,   2,   0,   1,   0,   0,   0],\n",
       "       [  1,   1,   1,   2,   1,   0,  10, 354,   7,   1,   0,   0,   9,\n",
       "          1,   3,   0,   4,   0,   1,   0],\n",
       "       [  0,   0,   0,   1,   0,   0,   4,   5, 385,   1,   0,   0,   1,\n",
       "          1,   0,   0,   0,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   3,   0,   0, 361,  31,   0,   0,\n",
       "          0,   0,   0,   1,   0,   0,   0],\n",
       "       [  0,   0,   0,   0,   1,   0,   0,   0,   0,   3, 393,   0,   0,\n",
       "          0,   0,   2,   0,   0,   0,   0],\n",
       "       [  1,   1,   1,   0,   2,   0,   3,   3,   0,   0,   1, 380,   1,\n",
       "          1,   0,   0,   1,   0,   1,   0],\n",
       "       [  8,   5,   9,  27,  11,   4,   7,   9,   6,   5,   4,  26, 243,\n",
       "          5,  13,   6,   2,   1,   2,   0],\n",
       "       [  2,   4,   0,   0,   2,   2,   4,   0,   3,   3,   4,   1,   6,\n",
       "        343,   2,   7,   3,   4,   5,   1],\n",
       "       [  0,   3,   0,   0,   1,   0,   2,   0,   0,   0,   1,   1,   0,\n",
       "          3, 380,   2,   0,   0,   1,   0],\n",
       "       [ 11,   0,   2,   1,   0,   0,   0,   0,   1,   0,   0,   0,   2,\n",
       "          1,   4, 371,   0,   0,   0,   5],\n",
       "       [  0,   0,   0,   1,   1,   0,   2,   2,   1,   2,   2,   5,   0,\n",
       "          1,   3,   0, 340,   1,   2,   1],\n",
       "       [ 11,   1,   0,   0,   1,   4,   0,   1,   0,   2,   2,   1,   0,\n",
       "          1,   1,   1,   1, 348,   1,   0],\n",
       "       [  3,   1,   0,   0,   1,   1,   1,   0,   1,   0,   3,   4,   0,\n",
       "          4,   7,   3, 102,   5, 174,   0],\n",
       "       [ 43,   1,   1,   0,   0,   0,   2,   2,   0,   1,   1,   1,   0,\n",
       "          4,   6,  60,  21,   6,   4,  98]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics.confusion_matrix(twenty_test.target,y_pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset...\n",
      "Extracting tf features for LDA...\n",
      "Fitting LDA models with tf features, n_samples=2000 and n_features=1000...\n",
      "\n",
      "Topics in LDA model:\n",
      "Topic #0:\n",
      "edu com mail send graphics ftp pub available contact university list faq ca information cs 1993 program sun uk mit\n",
      "Topic #1:\n",
      "don like just know think ve way use right good going make sure ll point got need really time doesn\n",
      "Topic #2:\n",
      "christian think atheism faith pittsburgh new bible radio games alt lot just religion like book read play time subject believe\n",
      "Topic #3:\n",
      "drive disk windows thanks use card drives hard version pc software file using scsi help does new dos controller 16\n",
      "Topic #4:\n",
      "hiv health aids disease april medical care research 1993 light information study national service test led 10 page new drug\n",
      "Topic #5:\n",
      "god people does just good don jesus say israel way life know true fact time law want believe make think\n",
      "Topic #6:\n",
      "55 10 11 18 15 team game 19 period play 23 12 13 flyers 20 25 22 17 24 16\n",
      "Topic #7:\n",
      "car year just cars new engine like bike good oil insurance better tires 000 thing speed model brake driving performance\n",
      "Topic #8:\n",
      "people said did just didn know time like went think children came come don took years say dead told started\n",
      "Topic #9:\n",
      "key space law government public use encryption earth section security moon probe enforcement keys states lunar military crime surface technology\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from __future__ import print_function\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "n_samples = 2000\n",
    "n_features = 1000\n",
    "n_topics = 10\n",
    "n_top_words = 20\n",
    "\n",
    "\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()\n",
    "\n",
    "\n",
    "# Load the 20 newsgroups dataset and vectorize it. We use a few heuristics\n",
    "# to filter out useless terms early on: the posts are stripped of headers,\n",
    "# footers and quoted replies, and common English words, words occurring in\n",
    "# only one document or in at least 95% of the documents are removed.\n",
    "\n",
    "print(\"Loading dataset...\")\n",
    "dataset = fetch_20newsgroups(shuffle=True, random_state=1,\n",
    "                             remove=('headers', 'footers', 'quotes'))\n",
    "data_samples = dataset.data[:n_samples]\n",
    "\n",
    "\n",
    "\n",
    "# Use tf (raw term count) features for LDA.\n",
    "print(\"Extracting tf features for LDA...\")\n",
    "tf_vectorizer = CountVectorizer(max_df=0.95, min_df=2,\n",
    "                                max_features=n_features,\n",
    "                                stop_words='english')\n",
    "tf = tf_vectorizer.fit_transform(data_samples)\n",
    "\n",
    "print(\"Fitting LDA models with tf features, \"\n",
    "      \"n_samples=%d and n_features=%d...\"\n",
    "      % (n_samples, n_features))\n",
    "lda = LatentDirichletAllocation(n_topics=n_topics, max_iter=5,\n",
    "                                learning_method='online',\n",
    "                                learning_offset=50.,\n",
    "                                random_state=0)\n",
    "\n",
    "lda.fit(tf)\n",
    "\n",
    "print(\"\\nTopics in LDA model:\")\n",
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, n_top_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
